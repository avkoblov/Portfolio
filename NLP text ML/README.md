# Описание проекта

Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Нам необходимо обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.

Построим модель со значением метрики качества F1 не меньше 0.75.

# Структура проекта

Загрузить и подготовить данные.
Обучить разные модели.
Сделать выводы.

# Описание данных

Данные находятся в файле toxic_comments.csv. Столбец text в нём содержит текст комментария, а toxic — целевой признак.

# Вывод
После предобработки и разделения данных на выборки были обучены три разные модели и предсказаны значения целевого признака. Получены следующие результаты работы моделей:

<br>LogisticRegression (время обучения порядка 6-7 секунд, значение метрики F1 = 0.76)
<br>CatBoost (время обучения около 3 минут, значение метрики F1 = 0.77)
<br>XGBoost (время обучения около 1 минуты, значение метрики F1 = 0.76)
<br>
<br>По результатам видно, что качество предсказаний моделей очень близко. Однако, сильно различается время обучения. Лидер по скорости обучения - ЛогистическаяРегрессия, самая простая из изученных моделей. На втором месте - XGBoost, время обучения которого выше logit, но XGBoost обеспечивает аналогичное ей качество предсказаний. В зависимости от потребностей и возможностей заказчика в момент запуска, можно рекомендовать для использования любую из двух отличившихся моделей. CatBoost дает лучшие из примеров результаты качества, но в данном случае обучается гораздо дольше других. В случае необходимости остановиться на одной модели, лучшие комплексные показатели - у Логистической регрессии, рекомендую использовать ее.
